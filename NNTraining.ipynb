{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGULBroRugj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import os,keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruhFj4ORSIHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_learning_set = \"/content/gdrive/My Drive/MIDI_files\"\n",
        "path_to_note_file = \"/content/gdrive/My Drive/Notes\"\n",
        "path_to_model = \"/content/gdrive/My Drive/Model.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZz5YxZRTLxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.002\n",
        "epochs_number = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Gje77NTNmF",
        "colab_type": "code",
        "outputId": "1665f418-f8e5-4d44-86a2-60ddbb0b3ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  tpu_adress = 'grpc://' + device_name\n",
        "  print('TPU found at: {}'.format(tpu_adress))\n",
        "\n",
        "except KeyError:\n",
        "  print('No TPU found. Chill. We can fix it.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u18JW7RnUfDU",
        "colab_type": "code",
        "outputId": "b8bddbe1-658e-4690-b713-17222373b74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwK1UnDkUff3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc60d79b-831e-4c38-809e-284855af20b9"
      },
      "source": [
        "notes = []\n",
        "\n",
        "for file in glob.glob(path_to_learning_set + \"/test/*.mid\"):\n",
        "    midi = converter.parse(file) # parsing midi to notes and chords\n",
        "\n",
        "    print('Parsing:', plik)\n",
        "\n",
        "    notes_to_parse = None\n",
        "\n",
        "    # for midi with many instruments\n",
        "    try:\n",
        "        parts = sorted(instrument.partitionByInstrument(midi).parts, key=lambda p: len(p), reverse=True)\n",
        "        for r in parts:\n",
        "            ins = r.getInstrument()\n",
        "            if 'Percussion' in ins.classes or 'Piano' in ins.classes:\n",
        "                continue\n",
        "            else:\n",
        "                notes_to_parse = p.recurse()\n",
        "                break\n",
        "        else:\n",
        "          notes_to_parse = part[0].recurse()\n",
        "    except AttributeError: #TODO: i'm not sure what error does partitionByInstrument raise but some day i will be\n",
        "        notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for sound in notes_to_parse:\n",
        "        if isinstance(sound, note.Note): # if it is one note\n",
        "            notes.append(str(sound.pitch))\n",
        "        elif isinstance(sound, chord.Chord): # if it is chord, save notes seperated by dot\n",
        "            notes.append('.'.join(str(n) for n in sound.normalOrder))\n",
        "\n",
        "# Parse songs from midi to strings\n",
        "with open(path_to_note_file, 'wb') as path:\n",
        "    pickle.dump(notes, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkfRYdedXddF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 100\n",
        "\n",
        "# all sounds names\n",
        "sounds_names = sorted(set(notes))\n",
        "\n",
        "number_of_sounds = len(sounds_names) # number of possible sounds\n",
        "\n",
        "# maping\n",
        "notes_in_int = dict((n, i) for i, n in enumerate(sounds_names))\n",
        "\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "for i in range(0, len(notes) - sequence_length):\n",
        "    sequence_input = notes[i:i + sequence_length] # we take this many -> number_of_sounds, notes and put them in sequence_input\n",
        "    sequence_output = notes[i + sequence_length] # and one sound that is after that sequence\n",
        "    network_input.append([notes_in_int[n] for n in sequence_input]) # to input we put int representation of sequance\n",
        "    network_output.append(notes_in_int[sequence_output]) # to output we put int represnation of next note\n",
        "\n",
        "number_of_patterns = len(network_input) # how many records we have, every record is sequence of sounds + one sound after that sequnce\n",
        "\n",
        "network_input = np.reshape(network_input, (number_of_patterns, sequence_length, 1))\n",
        "network_input = network_input / float(number_of_sounds)\n",
        "\n",
        "network_output = np_utils.to_categorical(network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IV0L9_-h0zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "4f634bda-2e9f-4fa5-9707-9b6738b02cf2"
      },
      "source": [
        "tf.config.experimental_connect_to_host(tpu_adress)\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_adress)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  # creating optimizer\n",
        "  opt = tf.compat.v1.train.RMSPropOptimizer(learning_rate)\n",
        " \n",
        "        \n",
        "\n",
        "  input_layer=tf.keras.layers.Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
        "  x=tf.keras.layers.LSTM(512, return_sequences=True)(input_layer)\n",
        "  x=tf.keras.layers.Dropout(0.3)(x)\n",
        "  x=tf.keras.layers.LSTM(512, return_sequences=True)(x)\n",
        "  x=tf.keras.layers.Dropout(0.3)(x)\n",
        "  x=tf.keras.layers.LSTM(512)(x)\n",
        "  x=tf.keras.layers.Dense(256)(x)\n",
        "  x=tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "  # output layer must have as many neurones as possible notes in our program\n",
        "  output_layer = tf.keras.layers.Dense(number_of_sounds, activation='softmax')(x)\n",
        "  model_f=tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "  model_f.compile(loss='categorical_crossentropy', optimizer=opt)  # kompilacja modelu\n",
        "\n",
        "  \n",
        "# konwersja modelu biblioteki Keras na model TensorFlow przystosowany do pracy z TPU\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69BA2wRuiYDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving better moodels\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    path_to_model,\n",
        "    monitor='loss',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu5yMcespcrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "905e6873-0d11-456c-e63e-ec6b3fcfd5d9"
      },
      "source": [
        "# newtork training\n",
        "model_f.fit(network_input, network_output, epochs=epochs_number, batch_size=1024, callbacks=[callback_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NNTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python38064bit9cd4904197744e9c979a4a675e295a1f",
      "display_name": "Python 3.8.0 64-bit"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}